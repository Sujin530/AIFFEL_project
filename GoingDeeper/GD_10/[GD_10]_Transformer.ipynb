{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uw0_tpBcRBAm"
      },
      "source": [
        "# [GD-10] Transformer로 번역기 만들기\n",
        "## 프로젝트: 더 멋진 번역기 만들기\n",
        "\n",
        "### 목차\n",
        "#### 1. 들어가며     \n",
        "  1-1. Transformer \n",
        "#### 2. 프로젝트       \n",
        "  2-1. 준비 및 설치       \n",
        "  2-2. 준비 및 설치         \n",
        "  2-2. 데이터 다운로드 (클라우드 유저용)         \n",
        "  2-3. 데이터 정제 및 토큰화         \n",
        "  2-4. 모델 설계        \n",
        "  2-5. 모듈 조립하기       \n",
        "  2-6. 훈련하기               \n",
        "  2-7. 결과 확인                 \n",
        "#### 3. 회고         \n",
        "  3-1. 최종 정리         \n",
        "  3-2. 참고사이트         \n",
        "\n",
        "### 루브릭 평가 기준\n",
        "|평가문항|상세기준|\n",
        "|:---|:---|\n",
        "|1. 번역기 모델 학습에 필요한 텍스트 데이터 전처리가 잘 이루어졌다.|데이터 정제, SentencePiece를 활용한 토큰화 및 데이터셋 구축의 과정이 지시대로 진행되었다.|\n",
        "|2. Transformer 번역기 모델이 정상적으로 구동된다.|Transformer 모델의 학습과 추론 과정이 정상적으로 진행되어, 한-영 번역기능이 정상 동작한다.|\n",
        "|3. 테스트 결과 의미가 통하는 수준의 번역문이 생성되었다.|제시된 문장에 대한 그럴듯한 영어 번역문이 생성되며, 시각화된 Attention Map으로 결과를 뒷받침한다.|   \n",
        "<br/>\n",
        "\n",
        "----\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. 들어가며\n",
        "### 1-1. Transformer\n",
        "* 기존의 seq2seq의 구조인 인코더-디코더를 따르면서도, 논문의 이름처럼 어텐션(Attention)만으로 구현한 모델\n",
        "* RNN을 사용하지 않고, 인코더-디코더 구조를 설계하였음에도 번역 성능에서도 RNN보다 우수한 성능을 보여줌\n",
        "\n",
        "* 트랜스포머 전체 코드       \n",
        "  https://github.com/ukairia777/tensorflow-transformer\n",
        "\n"
      ],
      "metadata": {
        "id": "fM2ftq3oG0Mk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. 프로젝트\n",
        "### 2-1. 준비 및 설치"
      ],
      "metadata": {
        "id": "oAbaWgpxHht5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Google Drive Connect"
      ],
      "metadata": {
        "id": "nDbwdSIEg4F0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# connect google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "d3tQHuh2g1ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94ae690e-befc-456f-a922-c4b97a1b48c5"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 한글 글씨 설치"
      ],
      "metadata": {
        "id": "a7htzLKdMM46"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "LE6q_VFrMM46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afa0e0f8-5e82-43a4-ff94-46fd13ab1c5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "fonts-nanum is already the newest version (20170925-1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n",
            "/usr/share/fonts: caching, new cache contents: 0 fonts, 1 dirs\n",
            "/usr/share/fonts/truetype: caching, new cache contents: 0 fonts, 3 dirs\n",
            "/usr/share/fonts/truetype/humor-sans: caching, new cache contents: 1 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/liberation: caching, new cache contents: 16 fonts, 0 dirs\n",
            "/usr/share/fonts/truetype/nanum: caching, new cache contents: 10 fonts, 0 dirs\n",
            "/usr/local/share/fonts: caching, new cache contents: 0 fonts, 0 dirs\n",
            "/root/.local/share/fonts: skipping, no such directory\n",
            "/root/.fonts: skipping, no such directory\n",
            "/var/cache/fontconfig: cleaning cache directory\n",
            "/root/.cache/fontconfig: not cleaning non-existent cache directory\n",
            "/root/.fontconfig: not cleaning non-existent cache directory\n",
            "fc-cache: succeeded\n"
          ]
        }
      ],
      "source": [
        "!sudo apt-get install -y fonts-nanum\n",
        "!sudo fc-cache -fv\n",
        "!rm ~/.cache/matplotlib -rf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### SentencePiece Tokenizer 패키지 설치"
      ],
      "metadata": {
        "id": "F4Rkr0Yt9Jcg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbemKrSK9JRC",
        "outputId": "bd1885e2-737b-4799-eaef-7c63d7012637"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 라이브러리 버전 확인"
      ],
      "metadata": {
        "id": "wVBY9DFMjw89"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7d8BHeY7j2lJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "daf8a43a-6d71-4741-9a49-85a71c49969e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.8.0\n",
            "1.21.5\n",
            "3.2.2\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import re\n",
        "import os\n",
        "import io\n",
        "import time\n",
        "import random\n",
        "\n",
        "import seaborn # Attention 시각화를 위해 필요!\n",
        "\n",
        "print(tf.__version__)\n",
        "print(np.__version__)\n",
        "print(matplotlib.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2-2. 데이터 다운로드 (클라우드 유저용)\n",
        "* ```korean-english-park.train.tar.gz``` 를 사용할 예정\n",
        "\n",
        "* jungyeul/korean-parallel-corpora.    \n",
        "  https://github.com/jungyeul/korean-parallel-corpora/tree/master/korean-english-news-v1\n",
        "\n",
        " "
      ],
      "metadata": {
        "id": "kotI0rg9j2sg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2-3. 데이터 정제 및 토큰화\n",
        "* ```set``` 데이터형이 중복을 허용하지 않는다는 것을 활용해 중복된 데이터를 제거\n",
        "* 데이터의 병렬 쌍이 흐트러지지 않게 주의\n",
        "* 중복을 제거한 데이터를 ```cleaned_corpus``` 에 저장합니다."
      ],
      "metadata": {
        "id": "8VoW_6M5j21s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "NbPTN5yUj21t"
      },
      "outputs": [],
      "source": [
        "data_dir = '/content/drive/MyDrive/ColabNotebooks/GoingDeeper/GD_10/transformer/data'\n",
        "kor_path = data_dir+\"/korean-english-park.train.ko\"\n",
        "eng_path = data_dir+\"/korean-english-park.train.en\"\n",
        "\n",
        "# 데이터 정제 및 토큰화\n",
        "def clean_corpus(kor_path, eng_path):\n",
        "    with open(kor_path, \"r\") as f: kor = f.read().splitlines()\n",
        "    with open(eng_path, \"r\") as f: eng = f.read().splitlines()\n",
        "    assert len(kor) == len(eng)\n",
        "\n",
        "    # [[YOUR CODE]]\n",
        "    cleaned_corpus = list(set(zip(kor, eng)))\n",
        "\n",
        "    return cleaned_corpus\n",
        "\n",
        "cleaned_corpus = clean_corpus(kor_path, eng_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "y1zwuS1kj26m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3413a8e-afb6-4125-9166-a89cda83e5e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "78968\n"
          ]
        }
      ],
      "source": [
        "print(len(cleaned_corpus))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "uNSAUxX3j27F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3cc360e-75f2-41ae-f8b8-1921243bf32d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('청와대에서는 강장관의 “피로 누적”에 따른 사퇴 의사를 수용한 것이라고 발표했지만 강장관의 교체 배경에 대한 의혹은 여전히 남아 있다고 코리아 타임즈는 보도했다.', 'The Korea Times reports Kang\\'s dismissal was met with disbelief, although the Presidential office indicated it accepted her wish to step down because she has been complaining of \"\"fatigue.'), ('양측은 또한 지구 온난화와 새 국제 형사 재판소를 포함한 광범위한 문제에 대해 견해 차이를 보여왔다.', 'The two sides have also had spats over a wide range of issues including global warming and the new International Criminal Court.'), ('루이지애나 주립 교도소 또는 앵골라 감옥은 그 사이즈가 맨해튼과 비슷하며 3면이 미시시피강으로 둘러싸여 있다.', 'The Louisiana State Penitentiary, or Angola Prison, is the size of Manhattan and surrounded on three sides by the Mississippi River.'), ('할리우드 작가조합의 파업철회로 한 숨 돌린 아카데미 시상식조직 위원회가 여느 때처럼 멋진 옷을 입은 배우들로 가득 찬 시상식을 약속했다.', 'BEVERLY HILLS, California (CNN) The end of the Hollywood writers strike means the Oscar show will be the usual star-studded, fashion-filled extravaganza, organizers promised.'), ('일기예보와 관계없이 비가 내리던 햇살이 눈을 가리던 포틀랜드는 관광객들에게 무한한 구경거리와 경험을 제공한다.', \"No matter what the weather forecast sun-drenched or soaking Portland has plenty of fun to offer visitors willing to snoop out this city's more eclectic and inviting destinations.\"), ('˝대통령 안보 고문은 어제 23명의 한국인 인질 중 한 명을 살해한 것에 대해 탈레반을 비난하는 성명을 발표했다.', '˝The presidential security council yesterday issued a statement denouncing the Taliban for killing one of the 23 Korean captives.'), ('올해 미국은 아프가니스탄에, 아프간 자국군의 설립을 위해 100억 달러를 지원할 예정이다.', 'This year the US is giving Afghanistan $10 billion, targeted at building up the country´s own security forces.˝'), ('Al-Qaeda names a successor to Abu Musab al-Zarqawi알카에다, 알-자르카위 후계자 지명2006.08', 'Al-Qaeda in Iraq has named a successor to Abu Musab al-Zarqawi, days after he was killed in a US air strike.'), ('안전 기준은 자주 지켜지지 않고 운항중인 여객선들은 열악한 환경에서 허용치보다 더 많은 탑승객을 실어 나르고 있는 실정이다.', 'Safety standards are often not enforced, meaning boats are in poor condition and carry more passengers than regulations allow.'), ('후쿠이 도시히코 현 총재의 임기는 19일에 만료된다. 일본은행 총재의 임기는 5년이다.', 'The five-year term of current Bank of Japan Governor Toshihiko Fukui ends Wednesday.')]\n"
          ]
        }
      ],
      "source": [
        "print(cleaned_corpus[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) 정제 함수를 아래 조건을 만족하게 정의하세요.\n",
        "* 모든 입력을 소문자로 변환합니다.\n",
        "* 알파벳, 문장부호, 한글만 남기고 모두 제거합니다.\n",
        "* 문장부호 양옆에 공백을 추가합니다.\n",
        "* 문장 앞뒤의 불필요한 공백을 제거합니다.\n"
      ],
      "metadata": {
        "id": "Mh_5J6TNj279"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "EpwwJOh0j279"
      },
      "outputs": [],
      "source": [
        "def preprocess_sentence(sentence, s_token=False, e_token=False):\n",
        "    sentence = sentence.lower().strip()\n",
        "\n",
        "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence)\n",
        "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
        "    sentence = re.sub(r\"[^a-zA-Z?.!,0-9^ㄱ-ㅎㅏ-ㅣ가-힣]+\", \" \", sentence)\n",
        "\n",
        "    sentence = sentence.strip()\n",
        "    \n",
        "    return sentence\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) 한글 말뭉치 ```kor_corpus``` 와 영문 말뭉치 ```eng_corpus``` 를 각각 분리한 후, 정제하여 토큰화를 진행합니다! 토큰화에는 Sentencepiece를 활용하세요. 첨부된 공식 사이트를 참고해 아래 조건을 만족하는 ```generate_tokenizer()``` 함수를 정의합니다. 최종적으로 ```ko_tokenizer``` 과 ```en_tokenizer``` 를 얻으세요. ```en_tokenizer```에는 ```set_encode_extra_options(\"bos:eos\")``` 함수를 실행해 타겟 입력이 문장의 시작 토큰과 끝 토큰을 포함할 수 있게 합니다.\n",
        "\n",
        "* 단어 사전을 매개변수로 받아 원하는 크기의 사전을 정의할 수 있게 합니다. (기본: 20,000)\n",
        "* 학습 후 저장된 model 파일을 SentencePieceProcessor() 클래스에 Load()한 후 반환합니다.\n",
        "* 특수 토큰의 인덱스를 아래와 동일하게 지정합니다.\n",
        "<PAD> : 0 / <BOS> : 1 / <EOS> : 2 / <UNK> : 3"
      ],
      "metadata": {
        "id": "TGdPXv4Bj28W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "kor_corpus = []\n",
        "eng_corpus = []\n",
        "\n",
        "for i in range(len(cleaned_corpus)):\n",
        "    kor_corpus.append(preprocess_sentence(cleaned_corpus[i][0]))\n",
        "    eng_corpus.append(preprocess_sentence(cleaned_corpus[i][1]))"
      ],
      "metadata": {
        "id": "nPL91Zv683ON"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(kor_corpus))\n",
        "print(len(eng_corpus))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WT9LKhQ86NJ",
        "outputId": "9fba9f19-ac1c-4ac4-eb6b-6026def81963"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "78968\n",
            "78968\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(kor_corpus[:2])\n",
        "print(eng_corpus[:2])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0p--O2w88pd",
        "outputId": "d6aa1a7b-0956-46b2-c7e0-dd2302f88bae"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['청와대에서는 강장관의 피로 누적 에 따른 사퇴 의사를 수용한 것이라고 발표했지만 강장관의 교체 배경에 대한 의혹은 여전히 남아 있다고 코리아 타임즈는 보도했다 .', '양측은 또한 지구 온난화와 새 국제 형사 재판소를 포함한 광범위한 문제에 대해 견해 차이를 보여왔다 .']\n",
            "['the korea times reports kang s dismissal was met with disbelief , although the presidential office indicated it accepted her wish to step down because she has been complaining of fatigue .', 'the two sides have also had spats over a wide range of issues including global warming and the new international criminal court .']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "YbNELZFcj28W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c0380803-0584-4c0f-ba51-033b9b0a00e3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "\n",
        "# Sentencepiece를 활용하여 학습한 tokenizer를 생성합니다.\n",
        "def generate_tokenizer(corpus,\n",
        "                       vocab_size,\n",
        "                       lang,\n",
        "                       pad_id=0,\n",
        "                       bos_id=1,\n",
        "                       eos_id=2,\n",
        "                       unk_id=3):\n",
        "    file = \"./%s_corpus.txt\" % lang\n",
        "    model = \"%s_spm\" % lang\n",
        "\n",
        "    with open(file, 'w') as f:\n",
        "        for row in corpus: f.write(str(row) + '\\n')\n",
        "\n",
        "    import sentencepiece as spm\n",
        "    # sentencepiece 모델 학습\n",
        "    spm.SentencePieceTrainer.Train(\n",
        "        '--input=./%s --model_prefix=%s --vocab_size=%d'\\\n",
        "        % (file, model, vocab_size) + \\\n",
        "        '--pad_id==%d --bos_id=%d --eos_id=%d --unk_id=%d'\\\n",
        "        % (pad_id, bos_id, eos_id, unk_id)\n",
        "    )\n",
        "    # 모델 불러오기\n",
        "    tokenizer = spm.SentencePieceProcessor()\n",
        "    tokenizer.Load('%s.model' % model)\n",
        "\n",
        "    return tokenizer\n",
        "\n",
        "SRC_VOCAB_SIZE = TGT_VOCAB_SIZE = 20000\n",
        "\n",
        "ko_tokenizer = generate_tokenizer(kor_corpus, SRC_VOCAB_SIZE, lang=\"ko\")\n",
        "en_tokenizer = generate_tokenizer(eng_corpus, TGT_VOCAB_SIZE, lang=\"en\")\n",
        "en_tokenizer.set_encode_extra_options(\"bos:eos\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4) 토크나이저를 활용해 토큰의 길이가 50 이하인 데이터를 선별하여 ```src_corpus``` 와 ```tgt_corpus``` 를 각각 구축하고, 텐서 ```enc_train``` 과 ```dec_train``` 으로 변환하세요! (❗모든 데이터를 사용할 경우 학습에 굉장히 오랜 시간이 걸립니다.)\n"
      ],
      "metadata": {
        "id": "5COvZkrlj29R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "tr-Hd4JOj29R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158,
          "referenced_widgets": [
            "7a4dd426487c4b43bc58907f486989ca",
            "8923eaa8739543c69d9c44f34858fef0",
            "497b91e846994593bd9c730852c72b8e",
            "99b7e909aaf041cdaf855d2284095e42",
            "cba470411c564b4081dacab42b70ca86",
            "972b16061ec74cc69160abc440f107a4",
            "27fff28d92c5470489ab4176ea1ce0c6",
            "ee1f9f53b8a646f89f4ca25282986d45",
            "3c287607451f47fcb433fbc1183582bb",
            "ddb106bb353b400badd5684b99350bb2",
            "8454e3b2b2484ee094d09f76a1a08b93"
          ]
        },
        "outputId": "97b9ec72-ac1b-4ff8-b659-fb740da3b4c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  if __name__ == '__main__':\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/78968 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7a4dd426487c4b43bc58907f486989ca"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "71289\n",
            "71289\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm_notebook    # Process 과정을 보기 위해\n",
        "\n",
        "src_corpus = []\n",
        "tgt_corpus = []\n",
        "\n",
        "assert len(kor_corpus) == len(eng_corpus)\n",
        "\n",
        "# 토큰의 길이가 50 이하인 문장만 남깁니다. \n",
        "for idx in tqdm_notebook(range(len(kor_corpus))):\n",
        "    # [[YOUR CODE]]\n",
        "    src_tokens = ko_tokenizer.encode_as_ids(kor_corpus[idx])  # 문자열을 ids로 토크나이즈 \n",
        "    tgt_tokens = en_tokenizer.encode_as_ids(eng_corpus[idx])\n",
        "    \n",
        "    if (len(src_tokens) > 50): continue    \n",
        "    if (len(tgt_tokens) > 50): continue\n",
        "    src_corpus.append(src_tokens)\n",
        "    tgt_corpus.append(tgt_tokens)\n",
        "\n",
        "\n",
        "print(len(src_corpus))\n",
        "print(len(tgt_corpus))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "OeECV9Kkj29v"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "ougC_cYyj29v"
      },
      "outputs": [],
      "source": [
        "# 패딩처리를 완료하여 학습용 데이터를 완성합니다. \n",
        "enc_train = tf.keras.preprocessing.sequence.pad_sequences(src_corpus, padding='post')\n",
        "dec_train = tf.keras.preprocessing.sequence.pad_sequences(tgt_corpus, padding='post')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bKqIeky7j2_c"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "MhIga5qRj2_c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0da06544-a441-453c-d7b2-51faafd53612"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(71289, 50)\n"
          ]
        }
      ],
      "source": [
        "print(enc_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dec_train.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcPKTUKE-Xzy",
        "outputId": "be5198a0-a0e2-4967-9619-97df97b1f0f0"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(71289, 50)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2-4. 모델 설계\n",
        "오늘 배운 내용을 활용해서 Transformer 모델을 설계해보세요!"
      ],
      "metadata": {
        "id": "j87Bx5n8j2_6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Positinal Encoding"
      ],
      "metadata": {
        "id": "rs6r6DB7_gdj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "isGJ0EVSj2_6"
      },
      "outputs": [],
      "source": [
        "def positional_encoding(pos, d_model):\n",
        "    def cal_angle(position, i):\n",
        "        return position / np.power(10000, int(i) / d_model)\n",
        "\n",
        "    def get_posi_angle_vec(position):\n",
        "        return [cal_angle(position, i) for i in range(d_model)]\n",
        "\n",
        "    sinusoid_table = np.array([get_posi_angle_vec(pos_i) for pos_i in range(pos)])\n",
        "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])\n",
        "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])\n",
        "    return sinusoid_table\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Multi-Head Attention"
      ],
      "metadata": {
        "id": "1pLdWdhgj3AT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "uEXq9vBzj3AT"
      },
      "outputs": [],
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "        \n",
        "        self.depth = d_model // self.num_heads\n",
        "        \n",
        "        self.W_q = tf.keras.layers.Dense(d_model) # Linear Layer\n",
        "        self.W_k = tf.keras.layers.Dense(d_model)\n",
        "        self.W_v = tf.keras.layers.Dense(d_model)\n",
        "        \n",
        "        self.linear = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "    def scaled_dot_product_attention(self, Q, K, V, mask):\n",
        "        d_k = tf.cast(K.shape[-1], tf.float32)\n",
        "        QK = tf.matmul(Q, K, transpose_b=True)\n",
        "\n",
        "        \"\"\"\n",
        "        Scaled QK 값 구하기\n",
        "        \"\"\"\n",
        "        scaled_qk = QK / tf.math.sqrt(d_k)\n",
        "\n",
        "        if mask is not None: scaled_qk += (mask * -1e9) \n",
        "\n",
        "        \"\"\"\n",
        "        1. Attention Weights 값 구하기 -> attentions\n",
        "        2. Attention 값을 V에 곱하기 -> out\n",
        "        \"\"\" \n",
        "        attentions = tf.nn.softmax(scaled_qk, axis=-1)\n",
        "        out = tf.matmul(attentions, V)\n",
        "\n",
        "        return out, attentions\n",
        "        \n",
        "\n",
        "    def split_heads(self, x):\n",
        "        \"\"\"\n",
        "        Embedding을 Head의 수로 분할하는 함수\n",
        "\n",
        "        x: [ batch x length x emb ]\n",
        "        return: [ batch x length x heads x self.depth ]\n",
        "        \"\"\"\n",
        "        batch_size = x.shape[0]\n",
        "        split_x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "        split_x = tf.transpose(split_x, perm=[0, 2, 1, 3])\n",
        "\n",
        "        return split_x\n",
        "\n",
        "    def combine_heads(self, x):\n",
        "        \"\"\"\n",
        "        분할된 Embedding을 하나로 결합하는 함수\n",
        "\n",
        "        x: [ batch x length x heads x self.depth ]\n",
        "        return: [ batch x length x emb ]\n",
        "        \"\"\"\n",
        "        batch_size = x.shape[0]\n",
        "        combined_x = tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "        combined_x = tf.reshape(combined_x, (batch_size, -1, self.d_model))\n",
        "\n",
        "\n",
        "        return combined_x\n",
        "    \n",
        "\n",
        "    def call(self, Q, K, V, mask):\n",
        "        \"\"\"\n",
        "        아래 순서에 따라 소스를 작성하세요.\n",
        "\n",
        "        Step 1: Linear_in(Q, K, V) -> WQ, WK, WV\n",
        "        Step 2: Split Heads(WQ, WK, WV) -> WQ_split, WK_split, WV_split\n",
        "        Step 3: Scaled Dot Product Attention(WQ_split, WK_split, WV_split)\n",
        "                 -> out, attention_weights\n",
        "        Step 4: Combine Heads(out) -> out\n",
        "        Step 5: Linear_out(out) -> out\n",
        "\n",
        "        \"\"\"\n",
        "\n",
        "        WQ = self.W_q(Q)\n",
        "        WK = self.W_k(K)\n",
        "        WV = self.W_v(V)\n",
        "        \n",
        "        WQ_splits = self.split_heads(WQ)\n",
        "        WK_splits = self.split_heads(WK)\n",
        "        WV_splits = self.split_heads(WV)\n",
        "            \n",
        "        out, attention_weights = self.scaled_dot_product_attention(\n",
        "            WQ_splits, WK_splits, WV_splits, mask)\n",
        "    \t\t\t\t        \n",
        "        out = self.combine_heads(out)\n",
        "        out = self.linear(out)\n",
        "                \n",
        "        return out, attention_weights"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Position-wise Feed-Forward Network"
      ],
      "metadata": {
        "id": "c4y7DP9Cj3Aw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "YN8x2ijRj3Aw"
      },
      "outputs": [],
      "source": [
        "class PoswiseFeedForwardNet(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, d_ff):\n",
        "        super(PoswiseFeedForwardNet, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.d_ff = d_ff\n",
        "\n",
        "        self.fc1 = tf.keras.layers.Dense(d_ff, activation='relu')\n",
        "        self.fc2 = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "    def call(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.fc2(out)\n",
        "\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2-5. 모듈 조립하기\n",
        "#### Encoder 레이어 구현하기"
      ],
      "metadata": {
        "id": "OjQLI94q_tuA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, n_heads, d_ff, dropout):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "\n",
        "        self.enc_self_attn = MultiHeadAttention(d_model, n_heads)\n",
        "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
        "\n",
        "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
        "        \n",
        "    def call(self, x, mask):\n",
        "\n",
        "        \"\"\"\n",
        "        Multi-Head Attention\n",
        "        \"\"\"\n",
        "        residual = x\n",
        "        out = self.norm_1(x)\n",
        "        out, enc_attn = self.enc_self_attn(out, out, out, mask)\n",
        "        out = self.dropout(out)\n",
        "        out += residual\n",
        "        \n",
        "        \"\"\"\n",
        "        Position-Wise Feed Forward Network\n",
        "        \"\"\"\n",
        "        residual = out\n",
        "        out = self.norm_2(out)\n",
        "        out = self.ffn(out)\n",
        "        out = self.dropout(out)\n",
        "        out += residual\n",
        "        \n",
        "        return out, enc_attn"
      ],
      "metadata": {
        "id": "XTBzTOum_tnR"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Decoder 레이어 구현하기"
      ],
      "metadata": {
        "id": "5y9R7u0F_tgO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DecoderLayer 클래스를 작성하세요.\n",
        "\n",
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "\n",
        "        self.dec_self_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.enc_dec_attn = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
        "\n",
        "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.norm_3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
        "    \n",
        "    def call(self, x, enc_out, causality_mask, padding_mask):\n",
        "\n",
        "        \"\"\"\n",
        "        Masked Multi-Head Attention\n",
        "        \"\"\"\n",
        "        residual = x\n",
        "        out = self.norm_1(x)\n",
        "        out, dec_attn = self.dec_self_attn(out, out, out, padding_mask)\n",
        "        out = self.dropout(out)\n",
        "        out += residual\n",
        "\n",
        "        \"\"\"\n",
        "        Multi-Head Attention\n",
        "        \"\"\"\n",
        "        residual = out\n",
        "        out = self.norm_2(out)\n",
        "        out, dec_enc_attn = self.enc_dec_attn(out, enc_out, enc_out, causality_mask)\n",
        "        out = self.dropout(out)\n",
        "        out += residual\n",
        "        \n",
        "        \"\"\"\n",
        "        Position-Wise Feed Forward Network\n",
        "        \"\"\"\n",
        "        residual = out\n",
        "        out = self.norm_3(out)\n",
        "        out = self.ffn(out)\n",
        "        out = self.dropout(out)\n",
        "        out += residual\n",
        "\n",
        "        return out, dec_attn, dec_enc_attn"
      ],
      "metadata": {
        "id": "hy23fXhC_tY9"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Encoder & Decoder 클래스 정의"
      ],
      "metadata": {
        "id": "fbpEwwOc_tN_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self,\n",
        "                 n_layers,\n",
        "                 d_model,\n",
        "                 n_heads,\n",
        "                 d_ff,\n",
        "                 dropout):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.n_layers = n_layers\n",
        "        self.enc_layers = [EncoderLayer(d_model, n_heads, d_ff, dropout) \n",
        "                        for _ in range(n_layers)]\n",
        "        \n",
        "    def call(self, x, mask):\n",
        "        out = x\n",
        "    \n",
        "        enc_attns = list()\n",
        "        for i in range(self.n_layers):\n",
        "            out, enc_attn = self.enc_layers[i](out, mask)\n",
        "            enc_attns.append(enc_attn)\n",
        "        \n",
        "        return out, enc_attns"
      ],
      "metadata": {
        "id": "5N0GHr2g_s-2"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self,\n",
        "                 n_layers,\n",
        "                 d_model,\n",
        "                 n_heads,\n",
        "                 d_ff,\n",
        "                 dropout):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.n_layers = n_layers\n",
        "        self.dec_layers = [DecoderLayer(d_model, n_heads, d_ff, dropout) \n",
        "                            for _ in range(n_layers)]\n",
        "                            \n",
        "                            \n",
        "    def call(self, x, enc_out, causality_mask, padding_mask):\n",
        "        out = x\n",
        "    \n",
        "        dec_attns = list()\n",
        "        dec_enc_attns = list()\n",
        "        for i in range(self.n_layers):\n",
        "            out, dec_attn, dec_enc_attn = \\\n",
        "            self.dec_layers[i](out, enc_out, causality_mask, padding_mask)\n",
        "\n",
        "            dec_attns.append(dec_attn)\n",
        "            dec_enc_attns.append(dec_enc_attn)\n",
        "\n",
        "        return out, dec_attns, dec_enc_attns"
      ],
      "metadata": {
        "id": "FpPFSscHAA4w"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Transformer 완성하기"
      ],
      "metadata": {
        "id": "S6Ege76IADJl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "    def __init__(self,\n",
        "                 n_layers,\n",
        "                 d_model,\n",
        "                 n_heads,\n",
        "                 d_ff,\n",
        "                 src_vocab_size,\n",
        "                 tgt_vocab_size,\n",
        "                 pos_len,\n",
        "                 dropout=0.2,\n",
        "                 shared=True):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.d_model = tf.cast(d_model, tf.float32)\n",
        "\n",
        "        \"\"\"\n",
        "        1. Embedding Layer 정의\n",
        "        2. Positional Encoding 정의\n",
        "        3. Encoder / Decoder 정의\n",
        "        4. Output Linear 정의\n",
        "        5. Shared Weights\n",
        "        6. Dropout 정의\n",
        "        \"\"\"\n",
        "        self.enc_emb = tf.keras.layers.Embedding(src_vocab_size, d_model)\n",
        "        self.dec_emb = tf.keras.layers.Embedding(tgt_vocab_size, d_model)\n",
        "\n",
        "        self.pos_encoding = positional_encoding(pos_len, d_model)\n",
        "        self.dropout = tf.keras.layers.Dropout(dropout)\n",
        "\n",
        "        self.encoder = Encoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
        "        self.decoder = Decoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
        "\n",
        "        self.fc = tf.keras.layers.Dense(tgt_vocab_size)\n",
        "\n",
        "        self.shared = shared\n",
        "\n",
        "        if shared: self.fc.set_weights(tf.transpose(self.dec_emb.weights))\n",
        "\n",
        "\n",
        "    def embedding(self, emb, x):\n",
        "        \"\"\"\n",
        "        입력된 정수 배열을 Embedding + Pos Encoding\n",
        "        + Shared일 경우 Scaling 작업 포함\n",
        "\n",
        "        x: [ batch x length ]\n",
        "        return: [ batch x length x emb ]\n",
        "        \"\"\"\n",
        "        seq_len = x.shape[1]\n",
        "        out = emb(x)\n",
        "\n",
        "        if self.shared: out *= tf.math.sqrt(self.d_model)\n",
        "\n",
        "        out += self.pos_encoding[np.newaxis, ...][:, :seq_len, :]\n",
        "        out = self.dropout(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "        \n",
        "    def call(self, enc_in, dec_in, enc_mask, causality_mask, dec_mask):\n",
        "        \"\"\"\n",
        "        아래 순서에 따라 소스를 작성하세요.\n",
        "\n",
        "        Step 1: Embedding(enc_in, dec_in) -> enc_in, dec_in\n",
        "        Step 2: Encoder(enc_in, enc_mask) -> enc_out, enc_attns\n",
        "        Step 3: Decoder(dec_in, enc_out, mask)\n",
        "                -> dec_out, dec_attns, dec_enc_attns\n",
        "        Step 4: Out Linear(dec_out) -> logits\n",
        "        \"\"\"\n",
        "        \n",
        "        enc_in = self.embedding(self.enc_emb, enc_in)\n",
        "        dec_in = self.embedding(self.dec_emb, dec_in)\n",
        "\n",
        "        enc_out, enc_attns = self.encoder(enc_in, enc_mask)\n",
        "        \n",
        "        dec_out, dec_attns, dec_enc_attns = \\\n",
        "        self.decoder(dec_in, enc_out, causality_mask, dec_mask)\n",
        "        \n",
        "        logits = self.fc(dec_out)\n",
        "        \n",
        "        return logits, enc_attns, dec_attns, dec_enc_attns"
      ],
      "metadata": {
        "id": "a3jTcZUyAC_9"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Masking"
      ],
      "metadata": {
        "id": "61KeI_epAU1W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_padding_mask(seq):\n",
        "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "    return seq[:, tf.newaxis, tf.newaxis, :]\n",
        "\n",
        "def generate_causality_mask(src_len, tgt_len):\n",
        "    mask = 1 - np.cumsum(np.eye(src_len, tgt_len), 0)\n",
        "    return tf.cast(mask, tf.float32)\n",
        "\n",
        "def generate_masks(src, tgt):\n",
        "    enc_mask = generate_padding_mask(src)\n",
        "    dec_mask = generate_padding_mask(tgt)\n",
        "\n",
        "    dec_enc_causality_mask = generate_causality_mask(tgt.shape[1], src.shape[1])\n",
        "    dec_enc_mask = tf.maximum(enc_mask, dec_enc_causality_mask)\n",
        "\n",
        "    dec_causality_mask = generate_causality_mask(tgt.shape[1], tgt.shape[1])\n",
        "    dec_mask = tf.maximum(dec_mask, dec_causality_mask)\n",
        "\n",
        "    return enc_mask, dec_enc_mask, dec_mask"
      ],
      "metadata": {
        "id": "mpUfzF5JAUvy"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <PAD> 토큰 찾아내는 마스크 생성"
      ],
      "metadata": {
        "id": "CviDAmxVAUmp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch, length = 16, 20\n",
        "src_padding = 5\n",
        "tgt_padding = 15\n",
        "\n",
        "src_pad = tf.zeros(shape=(batch, src_padding))\n",
        "tgt_pad = tf.zeros(shape=(batch, tgt_padding))\n",
        "\n",
        "sample_data = tf.ones(shape=(batch, length))\n",
        "\n",
        "sample_src = tf.concat([sample_data, src_pad], axis=-1)\n",
        "sample_tgt = tf.concat([sample_data, tgt_pad], axis=-1)\n",
        "\n",
        "enc_mask, dec_enc_mask, dec_mask = \\\n",
        "generate_masks(sample_src, sample_tgt)\n",
        "\n",
        "fig = plt.figure(figsize=(7, 7))\n",
        "\n",
        "ax1 = fig.add_subplot(131)\n",
        "ax2 = fig.add_subplot(132)\n",
        "ax3 = fig.add_subplot(133)\n",
        "\n",
        "ax1.set_title('1) Encoder Mask')\n",
        "ax2.set_title('2) Encoder-Decoder Mask')\n",
        "ax3.set_title('3) Decoder Mask')\n",
        "\n",
        "ax1.imshow(enc_mask[:3, 0, 0].numpy(), cmap='Dark2')\n",
        "ax2.imshow(dec_enc_mask[0, 0].numpy(), cmap='Dark2')\n",
        "ax3.imshow(dec_mask[0, 0].numpy(), cmap='Dark2')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "gnxMuiWcAUe1",
        "outputId": "6d919f26-d936-43a0-8487-9e9093f4782b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 504x504 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2-6. 훈련하기\n",
        "앞서 필요한 것들을 모두 정의했기 때문에 우리는 훈련만 하면 됩니다! 아래 과정을 차근차근 따라가며 모델을 훈련하고, 예문에 대한 멋진 번역을 제출하세요!\n",
        "\n",
        "1) 2 Layer를 가지는 ```Transformer```를 선언하세요.\n",
        "(하이퍼파라미터는 자유롭게 조절합니다.)"
      ],
      "metadata": {
        "id": "Sb_velo2j4qu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_layers = 2\n",
        "d_model = 512\n",
        "n_heads = 8\n",
        "d_ff = 2048\n",
        "dropout = 0.3"
      ],
      "metadata": {
        "id": "TrXDe-ofAuEY"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "mW5KHamKMcK_"
      },
      "outputs": [],
      "source": [
        "transformer = Transformer(\n",
        "    n_layers= n_layers,\n",
        "    d_model = d_model,\n",
        "    n_heads=n_heads,\n",
        "    d_ff=d_ff,\n",
        "    src_vocab_size=SRC_VOCAB_SIZE,\n",
        "    tgt_vocab_size=TGT_VOCAB_SIZE,\n",
        "    pos_len=200,\n",
        "    dropout=dropout,\n",
        "    shared=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ```LearningRateSchedule``` 클래스 상속"
      ],
      "metadata": {
        "id": "GC6TI-EgAkjl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LearningRateScheduler(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def __init__(self, d_model, warmup_steps=4000):\n",
        "        super(LearningRateScheduler, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.warmup_steps = warmup_steps\n",
        "    \n",
        "    def __call__(self, step):\n",
        "        arg1 = step ** -0.5\n",
        "        arg2 = step * (self.warmup_steps ** -1.5)\n",
        "        \n",
        "        return (self.d_model ** -0.5) * tf.math.minimum(arg1, arg2)\n",
        "\n",
        "learning_rate = LearningRateScheduler(d_model)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate,\n",
        "                                     beta_1=0.9,\n",
        "                                     beta_2=0.98, \n",
        "                                     epsilon=1e-9)"
      ],
      "metadata": {
        "id": "OdL6eliUAkcj"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) 논문에서 사용한 것과 동일한 Learning Rate Scheduler를 선언하고, 이를 포함하는 Adam Optimizer를 선언하세요. (Optimizer의 파라미터 역시 논문과 동일하게 설정합니다.)\n"
      ],
      "metadata": {
        "id": "k2cf5GOyj4yi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = LearningRateScheduler(d_model)"
      ],
      "metadata": {
        "id": "bLZZ1gZIBagW"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "LMYiUpWEj4yi"
      },
      "outputs": [],
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate,\n",
        "                                     beta_1=0.9,\n",
        "                                     beta_2=0.98, \n",
        "                                     epsilon=1e-9)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3) Loss 함수를 정의하세요.\n",
        "Sequence-to-sequence 모델에서 사용했던 Loss와 유사하되, Masking 되지 않은 입력의 개수로 Scaling하는 과정을 추가합니다. (트랜스포머가 모든 입력에 대한 Loss를 한 번에 구하기 때문입니다.)"
      ],
      "metadata": {
        "id": "bL2FjgVUj40L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "3Y0_6dHaj40L"
      },
      "outputs": [],
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    # Masking 되지 않은 입력의 개수로 Scaling하는 과정\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4) train_step 함수를 정의하세요.\n",
        "입력 데이터에 알맞은 Mask를 생성하고, 이를 모델에 전달하여 연산에서 사용할 수 있게 합니다."
      ],
      "metadata": {
        "id": "_DmQdrZTj41i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "8fai-y8xj41i"
      },
      "outputs": [],
      "source": [
        "# Train Step 함수 정의\n",
        "\n",
        "@tf.function()\n",
        "def train_step(src, tgt, model, optimizer):\n",
        "    tgt_in = tgt[:, :-1] \n",
        "    gold = tgt[:, 1:]\n",
        "        \n",
        "    enc_mask, dec_enc_mask, dec_mask = generate_masks(src, tgt_in)\n",
        "\n",
        "    # 계산된 loss에 tf.GradientTape()를 적용해 학습을 진행합니다.\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions, enc_attns, dec_attns, dec_enc_attns = \\\n",
        "        model(src, tgt_in, enc_mask, dec_enc_mask, dec_mask)\n",
        "        loss = loss_function(gold, predictions)\n",
        "\n",
        "    # 최종적으로 optimizer.apply_gradients()가 사용됩니다. \n",
        "    # [[YOUR CODE]]\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)    \n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "    \n",
        "    return loss, enc_attns, dec_attns, dec_enc_attns"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5) 학습을 진행합니다.\n",
        "매 Epoch 마다 제시된 예문에 대한 번역을 생성하고, 멋진 번역이 생성되면 그때의 하이퍼파라미터와 생성된 번역을 제출하세요!\n"
      ],
      "metadata": {
        "id": "oyVfWZGdj428"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 예문\n",
        "```\n",
        "1. 오바마는 대통령이다.\n",
        "2. 시민들은 도시 속에 산다.\n",
        "3. 커피는 필요 없다.\n",
        "4. 일곱 명의 사망자가 발생했다.\n",
        "````\n",
        "\n",
        "#### 결과(output)\n",
        "```\n",
        "Translations\n",
        "> 1. obama is the president elect .\n",
        "> 2. they are in the city .\n",
        "> 3. they don t need to be a lot of drink .\n",
        "> 4. seven other people have been killed in the attacks .\n",
        "\n",
        "Hyperparameters\n",
        "> n_layers: 2\n",
        "> d_model: 512\n",
        "> n_heads: 8\n",
        "> d_ff: 2048\n",
        "> dropout: 0.3\n",
        "\n",
        "Training Parameters\n",
        "> Warmup Steps: 4000\n",
        "> Batch Size: 64\n",
        "> Epoch At: 5\n",
        "```"
      ],
      "metadata": {
        "id": "4GhQGuap_DYf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "번역 생성에는 아래 소스를 사용하시길 바랍니다!"
      ],
      "metadata": {
        "id": "RwME7vmX_ImM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "AXfeky0cj428"
      },
      "outputs": [],
      "source": [
        "# Attention 시각화 함수\n",
        "\n",
        "def visualize_attention(src, tgt, enc_attns, dec_attns, dec_enc_attns):\n",
        "    def draw(data, ax, x=\"auto\", y=\"auto\"):\n",
        "        import seaborn\n",
        "        seaborn.heatmap(data, \n",
        "                        square=True,\n",
        "                        vmin=0.0, vmax=1.0, \n",
        "                        cbar=False, ax=ax,\n",
        "                        xticklabels=x,\n",
        "                        yticklabels=y)\n",
        "        \n",
        "    for layer in range(0, 2, 1):\n",
        "        fig, axs = plt.subplots(1, 4, figsize=(20, 10))\n",
        "        print(\"Encoder Layer\", layer + 1)\n",
        "        for h in range(4):\n",
        "            draw(enc_attns[layer][0, h, :len(src), :len(src)], axs[h], src, src)\n",
        "        plt.show()\n",
        "        \n",
        "    for layer in range(0, 2, 1):\n",
        "        fig, axs = plt.subplots(1, 4, figsize=(20, 10))\n",
        "        print(\"Decoder Self Layer\", layer+1)\n",
        "        for h in range(4):\n",
        "            draw(dec_attns[layer][0, h, :len(tgt), :len(tgt)], axs[h], tgt, tgt)\n",
        "        plt.show()\n",
        "\n",
        "        print(\"Decoder Src Layer\", layer+1)\n",
        "        fig, axs = plt.subplots(1, 4, figsize=(20, 10))\n",
        "        for h in range(4):\n",
        "            draw(dec_enc_attns[layer][0, h, :len(tgt), :len(src)], axs[h], src, tgt)\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "sFmdq4BPj44N"
      },
      "outputs": [],
      "source": [
        "# 번역 생성 함수\n",
        "\n",
        "def evaluate(sentence, model, src_tokenizer, tgt_tokenizer):\n",
        "    sentence = preprocess_sentence(sentence)\n",
        "\n",
        "    pieces = src_tokenizer.encode_as_pieces(sentence)\n",
        "    tokens = src_tokenizer.encode_as_ids(sentence)\n",
        "\n",
        "    _input = tf.keras.preprocessing.sequence.pad_sequences([tokens],\n",
        "                                                           maxlen=enc_train.shape[-1],\n",
        "                                                           padding='post')\n",
        "    \n",
        "    ids = []\n",
        "    output = tf.expand_dims([tgt_tokenizer.bos_id()], 0)\n",
        "    for i in range(dec_train.shape[-1]):\n",
        "        enc_padding_mask, combined_mask, dec_padding_mask = \\\n",
        "        generate_masks(_input, output)\n",
        "\n",
        "        predictions, enc_attns, dec_attns, dec_enc_attns =\\\n",
        "        model(_input, \n",
        "              output,\n",
        "              enc_padding_mask,\n",
        "              combined_mask,\n",
        "              dec_padding_mask)\n",
        "\n",
        "        predicted_id = \\\n",
        "        tf.argmax(tf.math.softmax(predictions, axis=-1)[0, -1]).numpy().item()\n",
        "\n",
        "        if tgt_tokenizer.eos_id() == predicted_id:\n",
        "            result = tgt_tokenizer.decode_ids(ids)\n",
        "            return pieces, result, enc_attns, dec_attns, dec_enc_attns\n",
        "\n",
        "        ids.append(predicted_id)\n",
        "        output = tf.concat([output, tf.expand_dims([predicted_id], 0)], axis=-1)\n",
        "\n",
        "    result = tgt_tokenizer.decode_ids(ids)\n",
        "\n",
        "    return pieces, result, enc_attns, dec_attns, dec_enc_attns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "_Klo_l8wj45h"
      },
      "outputs": [],
      "source": [
        "# 번역 생성 및 Attention 시각화 결합\n",
        "\n",
        "def translate(sentence, model, src_tokenizer, tgt_tokenizer, plot_attention=False):\n",
        "    pieces, result, enc_attns, dec_attns, dec_enc_attns = \\\n",
        "    evaluate(sentence, model, src_tokenizer, tgt_tokenizer)\n",
        "    \n",
        "    print('Input: %s' % (sentence))\n",
        "    print('Predicted translation: {}'.format(result))\n",
        "\n",
        "    if plot_attention:\n",
        "        visualize_attention(pieces, result.split(), enc_attns, dec_attns, dec_enc_attns)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 학습\n",
        "\n",
        "from tqdm import tqdm_notebook \n",
        "\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 20\n",
        "\n",
        "examples = [\n",
        "            \"오바마는 대통령이다.\",\n",
        "            \"시민들은 도시 속에 산다.\",\n",
        "            \"커피는 필요 없다.\",\n",
        "            \"일곱 명의 사망자가 발생했다.\"\n",
        "]\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    total_loss = 0\n",
        "    \n",
        "    idx_list = list(range(0, enc_train.shape[0], BATCH_SIZE))\n",
        "    random.shuffle(idx_list)\n",
        "    t = tqdm_notebook(idx_list)\n",
        "\n",
        "    for (batch, idx) in enumerate(t):\n",
        "        batch_loss, enc_attns, dec_attns, dec_enc_attns = \\\n",
        "        train_step(enc_train[idx:idx+BATCH_SIZE],\n",
        "                   dec_train[idx:idx+BATCH_SIZE],\n",
        "                   transformer,\n",
        "                   optimizer)\n",
        "\n",
        "        total_loss += batch_loss\n",
        "        \n",
        "        t.set_description_str('Epoch %2d' % (epoch + 1))\n",
        "        t.set_postfix_str('Loss %.4f' % (total_loss.numpy() / (batch + 1)))\n",
        "\n",
        "    for example in examples:\n",
        "        translate(example, transformer, ko_tokenizer, en_tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "7726925842ab4b02820fe44b0cc4b281",
            "b5912cbf96094705af0a646a95354e31",
            "3c9e329bb74b478b893c379964640da8",
            "706676325d5e499992d4c10589e33e69",
            "70b19f7a430c4072af29a7e2a2928881",
            "43d296bc93284a2d8ecb24e2184e2bbb",
            "940b820f2cc547a29a732cd0be824b26",
            "2d586b61395a48419ef4b72a89c910d0",
            "ea722ad1f57b4652b1ded73993ea5c50",
            "5cb05f8059d64235aec3bf5238c16f9a",
            "f951877ada48438daaa0fcac580e71fd"
          ]
        },
        "id": "Ktc-aJUaCvmr",
        "outputId": "5985ba88-95e1-454e-ee2b-d0a8bf957ae8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/1114 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7726925842ab4b02820fe44b0cc4b281"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2-7. 결과 확인"
      ],
      "metadata": {
        "id": "y4KtM8LQj5AI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JH_aEE1gj5AJ"
      },
      "outputs": [],
      "source": [
        "translate('오바마는 대통령이다.', transformer, ko_tokenizer, en_tokenizer, plot_attention=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Brks6KWk6ZF1"
      },
      "source": [
        "## 3. 회고\n",
        "\n",
        "### 3-1. 최종 정리\n",
        "* 학습하는데 시간이 오래 걸려 제출 전에 결과를 확인하지 못한 것이 아쉽다.       \n",
        "* 아직 Attention, Transformer 에 대한 개념이 제대로 잡히지 않아 노드와 다른 자료를 많이 참고하며 겨우 진행했다.     \n",
        "* 아쉽기는 하지만 하나씩 프로젝트를 할 때마다 조금씩 알게되는 것 같아서 프로젝트에 나온 개념만이라도 다시 정리해야겠다고 생각했다.  \n",
        "<br/>\n",
        "<br/>\n",
        "\n",
        "### 3-2. 참고사이트\n",
        "* 딥 러닝을 이용한 자연어 처리 입문   \n",
        "  https://wikidocs.net/31379      \n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4gvrn1ZVI8tD"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "[GD_10] Transformer",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7a4dd426487c4b43bc58907f486989ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8923eaa8739543c69d9c44f34858fef0",
              "IPY_MODEL_497b91e846994593bd9c730852c72b8e",
              "IPY_MODEL_99b7e909aaf041cdaf855d2284095e42"
            ],
            "layout": "IPY_MODEL_cba470411c564b4081dacab42b70ca86"
          }
        },
        "8923eaa8739543c69d9c44f34858fef0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_972b16061ec74cc69160abc440f107a4",
            "placeholder": "​",
            "style": "IPY_MODEL_27fff28d92c5470489ab4176ea1ce0c6",
            "value": "100%"
          }
        },
        "497b91e846994593bd9c730852c72b8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ee1f9f53b8a646f89f4ca25282986d45",
            "max": 78968,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3c287607451f47fcb433fbc1183582bb",
            "value": 78968
          }
        },
        "99b7e909aaf041cdaf855d2284095e42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ddb106bb353b400badd5684b99350bb2",
            "placeholder": "​",
            "style": "IPY_MODEL_8454e3b2b2484ee094d09f76a1a08b93",
            "value": " 78968/78968 [00:04&lt;00:00, 18041.16it/s]"
          }
        },
        "cba470411c564b4081dacab42b70ca86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "972b16061ec74cc69160abc440f107a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27fff28d92c5470489ab4176ea1ce0c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ee1f9f53b8a646f89f4ca25282986d45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c287607451f47fcb433fbc1183582bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ddb106bb353b400badd5684b99350bb2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8454e3b2b2484ee094d09f76a1a08b93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7726925842ab4b02820fe44b0cc4b281": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b5912cbf96094705af0a646a95354e31",
              "IPY_MODEL_3c9e329bb74b478b893c379964640da8",
              "IPY_MODEL_706676325d5e499992d4c10589e33e69"
            ],
            "layout": "IPY_MODEL_70b19f7a430c4072af29a7e2a2928881"
          }
        },
        "b5912cbf96094705af0a646a95354e31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_43d296bc93284a2d8ecb24e2184e2bbb",
            "placeholder": "​",
            "style": "IPY_MODEL_940b820f2cc547a29a732cd0be824b26",
            "value": "Epoch  1:  29%"
          }
        },
        "3c9e329bb74b478b893c379964640da8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d586b61395a48419ef4b72a89c910d0",
            "max": 1114,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ea722ad1f57b4652b1ded73993ea5c50",
            "value": 324
          }
        },
        "706676325d5e499992d4c10589e33e69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5cb05f8059d64235aec3bf5238c16f9a",
            "placeholder": "​",
            "style": "IPY_MODEL_f951877ada48438daaa0fcac580e71fd",
            "value": " 324/1114 [51:22&lt;2:12:03, 10.03s/it, Loss 7.4035]"
          }
        },
        "70b19f7a430c4072af29a7e2a2928881": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43d296bc93284a2d8ecb24e2184e2bbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "940b820f2cc547a29a732cd0be824b26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d586b61395a48419ef4b72a89c910d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea722ad1f57b4652b1ded73993ea5c50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5cb05f8059d64235aec3bf5238c16f9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f951877ada48438daaa0fcac580e71fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}